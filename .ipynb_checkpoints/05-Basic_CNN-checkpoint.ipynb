{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, ), (0.3801, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./dataset/mnist/',\n",
    "                               train=True,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./dataset/mnist/',\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         shuffle=False,\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./picture/CNN4.jpg', width=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='./picture/CNN4.jpg', width=600>\n",
    "# 3×5×5的输入图像与3×3×3的卷积核做卷积运算得到的是1×3×3的输出图像\n",
    "# 3×3的卷积核因为以最开始的4/6/8为中心，得到的特征图少上下共2行和左右共2列。5×5的则少上2行下2行，左2列，右2列\n",
    "# 对于stride为1的3×3卷积核做运算，要想得到原图像一样的尺寸，则需要padding=1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./picture/CNN3.jpg', width=600>\n",
       "<img src='./picture/CNN5.jpg', width=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='./picture/CNN3.jpg', width=600>\n",
    "<img src='./picture/CNN5.jpg', width=600>\n",
    "# 输入为n × h × w的图像经过一个卷积层，有m个卷积核，一个卷积核得到一个二维的特征图像，最后将m个特征图像拼接得到 m × h'× w'的图像\n",
    "# 因此，该卷积层的卷积核是一个四维的张量 (m×n×h`×w`)，其中m为卷积核个数，n为输入通道数，h`× w`为卷积核尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./picture/CNN1.jpg', width=600>\n",
       "<img src='./picture/CNN2.jpg', width=800>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='./picture/CNN1.jpg', width=600>\n",
    "<img src='./picture/CNN2.jpg', width=800>\n",
    "# 单通道28×28的图像经过第一层卷积运算，输出为10×24×24的特征图像，所以第一个卷积层卷积核设置为10×1×5×5\n",
    "# 经过第一个池化层得到10×12×12的特征图像，所以第一个池化层的卷积核设置为2×2 (注意:池化层的卷积核是取最大值或求平均而不是做点乘)\n",
    "# 经过第二层卷积运算，输出为20×8×8的特征图像，所以第二个卷积层卷积核设置为20×10×5×5\n",
    "# 经过第二个池化层得到20×4×4的特征图像，所以第二个池化层的卷积核设置为2×2\n",
    "# 最后经过一个全连接层将三位的特征矩阵拉乘一个向量，经过一个线性层得到10个输出。\n",
    "# 因为特征图像一共有20×4×4=320个像素值，且输出为10分类，所以线性层设置为(320×10)\n",
    "\n",
    "# 在实际中全连接层输入维度的设置，可以用pytorch设置一个随机的矩阵张量输入到神经网络中，然后直接查看最后一个输出层的输出尺寸，再计算\n",
    "# 具体见Torch-Randn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=320, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积核只与输入的通道数有关，对于输入图片的大小无所谓。一个卷积层中卷积核的个数决定了下一个卷积层卷积核的通道数\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)   # 卷积核尺寸为1×5×5,(其中1为通道数),个数为10\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)  # 卷积核尺寸为10×5×5, (其中10为通道数),个数为20\n",
    "        self.pooling = torch.nn.MaxPool2d(2)                 # 这里,最大池化层卷积核尺寸为2×2,默认步长为2\n",
    "        self.fc = torch.nn.Linear(320, 10)                   # \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten data from (n, 1, 28, 28) to (n, 784)\n",
    "        batch_size = x.size(0)                               # 除去最后一次迭代，x.size都为(64,1,28,28)\n",
    "        x = F.relu(self.pooling(self.conv1(x)))\n",
    "        x = F.relu(self.pooling(self.conv2(x)))\n",
    "        x = x.view(batch_size, -1)                           # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "# 将参数和所有模块的缓存转换为CUDA Tensor\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    run_loss = 0\n",
    "    for batch_idx, [inputs, labels] in enumerate(train_loader):\n",
    "        # 将输入输出的每一步加载到显卡上\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss += loss.item()\n",
    "        \n",
    "        if(batch_idx % 300 == 299):\n",
    "            print('[%d, %5d], loss: %.3f' % (epoch + 1, batch_idx + 1, run_loss / 300))\n",
    "            run_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for [inputs, labels] in test_loader:\n",
    "            # 将输入输出的每一步加载到显卡上\n",
    "            inputs, labels = inputs.to(device),labels.to(device) \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, pred = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %% [%d/%d]' % (100 * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300], loss: 0.668\n",
      "[1,   600], loss: 0.215\n",
      "[1,   900], loss: 0.153\n",
      "Accuracy on test set: 96 % [9655/10000]\n",
      "[2,   300], loss: 0.123\n",
      "[2,   600], loss: 0.105\n",
      "[2,   900], loss: 0.093\n",
      "Accuracy on test set: 97 % [9782/10000]\n",
      "[3,   300], loss: 0.083\n",
      "[3,   600], loss: 0.083\n",
      "[3,   900], loss: 0.081\n",
      "Accuracy on test set: 97 % [9780/10000]\n",
      "[4,   300], loss: 0.069\n",
      "[4,   600], loss: 0.069\n",
      "[4,   900], loss: 0.070\n",
      "Accuracy on test set: 98 % [9826/10000]\n",
      "[5,   300], loss: 0.060\n",
      "[5,   600], loss: 0.060\n",
      "[5,   900], loss: 0.063\n",
      "Accuracy on test set: 98 % [9838/10000]\n",
      "[6,   300], loss: 0.054\n",
      "[6,   600], loss: 0.055\n",
      "[6,   900], loss: 0.051\n",
      "Accuracy on test set: 98 % [9848/10000]\n",
      "[7,   300], loss: 0.051\n",
      "[7,   600], loss: 0.048\n",
      "[7,   900], loss: 0.051\n",
      "Accuracy on test set: 98 % [9870/10000]\n",
      "[8,   300], loss: 0.043\n",
      "[8,   600], loss: 0.048\n",
      "[8,   900], loss: 0.048\n",
      "Accuracy on test set: 98 % [9860/10000]\n",
      "[9,   300], loss: 0.041\n",
      "[9,   600], loss: 0.044\n",
      "[9,   900], loss: 0.042\n",
      "Accuracy on test set: 98 % [9863/10000]\n",
      "[10,   300], loss: 0.037\n",
      "[10,   600], loss: 0.040\n",
      "[10,   900], loss: 0.044\n",
      "Accuracy on test set: 98 % [9869/10000]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
