{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms     # transforms 将pytorch读取到了PIL图像转为图像张量Tensor的以方便神经网络进行训练\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIL或OpenCV读进来的图像张量一般都是H×W×C，为使神经网络进行更高效的训练一般转换为C×H×W且对像素值进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='picture/image.jpg', width=200>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='picture/image.jpg', width=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Compose([]), 可以把[]里一系列的对象进行一系列的处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                       # 将28×28的单通道图像转换为1×28×28的多通道的图像张量\n",
    "    transforms.Normalize((0.1307, ), (0.3801, )) # 将图像的像素值进行归一化方便神经网络训练,Normalize((mean, ), (std, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./dataset/mnist/',\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=transform) # 读取第i个数据样本时，拿到的数据会直接用transform进行处理\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./dataset/mnist/',\n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         shuffle=False,\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='picture/quanlianjie.jpg', width=700>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='picture/quanlianjie.jpg', width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512) \n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 全连接神经网络要求的输入样本是一个矩阵，因此对于N×1×28×28的图像，要将1×28×28三阶的张量变成一阶的向量即使用x.view()\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)  # 注意:最后一层不做激活，直接将最后一层线性层的输出，输入到softmax层进行CrossEntropyLoss运算\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) \n",
    "# momentum冲量，给数据处理一个惯性值，以从局部最优解走出来尽可能找到全局最优解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    # 一次送入 batch_size个样本，这里为64个， 样本总数为 64 × batch_idx\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        # input.size() 为[64, 1, 28, 28]， target.size() 为[64]\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每300次迭代输出一次\n",
    "        if batch_idx % 300 == 299:\n",
    "            # %5d表示的整型值占5位宽度，不足5位的话，在左边用空格补充\n",
    "            # %f默认输出小数点后6位; %.3f，表示保留3位小数位\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0                          # 正确的个数\n",
    "    total = 0                            # 总数\n",
    "    with torch.no_grad() :               # 使用torch.no_grad()在with里面的代码不会计算梯度\n",
    "        # test一共有10,000个数据, 所以这里一次test()循环157次\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            # 沿着第1个维度(行是第1个维度，列是第0个维度)去找最大值的下标,返回每一行的最大值和每一行的最大值下标\n",
    "            _, predicted = torch.max(outputs.data, dim=1)  \n",
    "            # total 前156次迭代一次加64， 最后一次迭代加剩余的样本数\n",
    "            total += labels.size(0)\n",
    "            # 每一次迭代都是判断64个predicted的值与64个labels的值是否相等，相等的个数为sum()的结果\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct / total)) # %% 表示输出为 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 2.266\n",
      "[1,   600] loss: 1.312\n",
      "[1,   900] loss: 0.498\n",
      "Accuracy on test set: 88 %\n",
      "[2,   300] loss: 0.375\n",
      "[2,   600] loss: 0.306\n",
      "[2,   900] loss: 0.267\n",
      "Accuracy on test set: 93 %\n",
      "[3,   300] loss: 0.224\n",
      "[3,   600] loss: 0.190\n",
      "[3,   900] loss: 0.178\n",
      "Accuracy on test set: 95 %\n",
      "[4,   300] loss: 0.152\n",
      "[4,   600] loss: 0.138\n",
      "[4,   900] loss: 0.140\n",
      "Accuracy on test set: 95 %\n",
      "[5,   300] loss: 0.116\n",
      "[5,   600] loss: 0.109\n",
      "[5,   900] loss: 0.105\n",
      "Accuracy on test set: 96 %\n",
      "[6,   300] loss: 0.089\n",
      "[6,   600] loss: 0.094\n",
      "[6,   900] loss: 0.086\n",
      "Accuracy on test set: 96 %\n",
      "[7,   300] loss: 0.073\n",
      "[7,   600] loss: 0.071\n",
      "[7,   900] loss: 0.074\n",
      "Accuracy on test set: 97 %\n",
      "[8,   300] loss: 0.060\n",
      "[8,   600] loss: 0.061\n",
      "[8,   900] loss: 0.057\n",
      "Accuracy on test set: 96 %\n",
      "[9,   300] loss: 0.047\n",
      "[9,   600] loss: 0.055\n",
      "[9,   900] loss: 0.048\n",
      "Accuracy on test set: 97 %\n",
      "[10,   300] loss: 0.037\n",
      "[10,   600] loss: 0.042\n",
      "[10,   900] loss: 0.042\n",
      "Accuracy on test set: 97 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
